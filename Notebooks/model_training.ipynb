{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stroke Prediction Model Training\n",
    "\n",
    "This notebook trains both baseline and improved models for comparison.\n",
    "\n",
    "**Note:** SMOTE has already been applied in `data_preprocessing.ipynb`\n",
    "\n",
    "**Sections:**\n",
    "1. Setup and Data Loading\n",
    "2. Baseline Model Training (6 algorithms)\n",
    "3. Improved Model Training (Hyperparameter Tuning)\n",
    "4. Model Comparison\n",
    "5. Save Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score,\n",
    "    precision_recall_curve, make_scorer\n",
    ")\n",
    "\n",
    "# Model improvement\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "print(\"âœ… Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: c:\\Users\\chigu\\Desktop\\stroke-prediction-project\\Notebooks\n",
      "Data path: ../Data/\n",
      "Models path: ../Models/\n"
     ]
    }
   ],
   "source": [
    "# Detect correct path\n",
    "current_dir = os.getcwd()\n",
    "if 'Notebooks' in current_dir:\n",
    "    data_path = '../Data/'\n",
    "    models_path = '../Models/'\n",
    "else:\n",
    "    data_path = 'Data/'\n",
    "    models_path = 'Models/'\n",
    "\n",
    "print(f\"Current directory: {current_dir}\")\n",
    "print(f\"Data path: {data_path}\")\n",
    "print(f\"Models path: {models_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data loaded successfully\n",
      "\n",
      "Training samples: 7778\n",
      "Test samples: 1022\n",
      "Features: ['gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'avg_glucose_level', 'bmi', 'smoking_status']\n",
      "\n",
      "Class distribution (train):\n",
      "  No Stroke: 3889\n",
      "  Stroke: 3889\n",
      "  Balance ratio: 1.00:1\n",
      "\n",
      "âœ… Data is already balanced (SMOTE was applied in preprocessing)\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed data (already SMOTE-balanced from data_preprocessing.ipynb)\n",
    "X_train = pd.read_csv(f'{data_path}X_train_preprocessed.csv')\n",
    "X_test = pd.read_csv(f'{data_path}X_test_preprocessed.csv')\n",
    "y_train = pd.read_csv(f'{data_path}y_train_preprocessed.csv').values.ravel()\n",
    "y_test = pd.read_csv(f'{data_path}y_test_preprocessed.csv').values.ravel()\n",
    "\n",
    "print(\"âœ… Data loaded successfully\")\n",
    "print(f\"\\nTraining samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Features: {list(X_train.columns)}\")\n",
    "print(f\"\\nClass distribution (train):\")\n",
    "print(f\"  No Stroke: {np.bincount(y_train)[0]}\")\n",
    "print(f\"  Stroke: {np.bincount(y_train)[1]}\")\n",
    "print(f\"  Balance ratio: {np.bincount(y_train)[0] / np.bincount(y_train)[1]:.2f}:1\")\n",
    "print(\"\\nâœ… Data is already balanced (SMOTE was applied in preprocessing)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Baseline Model Training\n",
    "\n",
    "Train 6 different models without hyperparameter tuning to establish baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BASELINE MODEL TRAINING\n",
      "======================================================================\n",
      "\n",
      "Training RandomForest...\n",
      "  Accuracy: 0.9022, Precision: 0.1212, Recall: 0.1600, F1: 0.1379\n",
      "\n",
      "Training XGBoost...\n",
      "  Accuracy: 0.8992, Precision: 0.1045, Recall: 0.1400, F1: 0.1197\n",
      "\n",
      "Training LogisticRegression...\n",
      "  Accuracy: 0.7857, Precision: 0.1494, Recall: 0.7200, F1: 0.2474\n",
      "\n",
      "Training SVM...\n",
      "  Accuracy: 0.7759, Precision: 0.1434, Recall: 0.7200, F1: 0.2392\n",
      "\n",
      "Training KNN...\n",
      "  Accuracy: 0.7945, Precision: 0.0876, Recall: 0.3400, F1: 0.1393\n",
      "\n",
      "Training NaiveBayes...\n",
      "  Accuracy: 0.7172, Precision: 0.1030, Recall: 0.6200, F1: 0.1766\n",
      "\n",
      "======================================================================\n",
      "BASELINE RESULTS\n",
      "======================================================================\n",
      "                    Accuracy  Precision  Recall  F1 Score\n",
      "RandomForest        0.902153   0.121212    0.16  0.137931\n",
      "XGBoost             0.899217   0.104478    0.14  0.119658\n",
      "LogisticRegression  0.785714   0.149378    0.72  0.247423\n",
      "SVM                 0.775930   0.143426    0.72  0.239203\n",
      "KNN                 0.794521   0.087629    0.34  0.139344\n",
      "NaiveBayes          0.717221   0.102990    0.62  0.176638\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"BASELINE MODEL TRAINING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=42, verbosity=0),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=500, random_state=42),\n",
    "    'SVM': SVC(kernel='linear', probability=True, random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'NaiveBayes': GaussianNB()\n",
    "}\n",
    "\n",
    "baseline_results = {}\n",
    "for name, model in models.items():\n",
    "    print(f'\\nTraining {name}...')\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    baseline_results[name] = {\n",
    "        'Accuracy': acc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    }\n",
    "    \n",
    "    print(f'  Accuracy: {acc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}')\n",
    "\n",
    "baseline_df = pd.DataFrame(baseline_results).T\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"BASELINE RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(baseline_df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Improved Model Training\n",
    "\n",
    "Apply improvements:\n",
    "- Hyperparameter tuning with GridSearchCV\n",
    "- Optimal threshold selection\n",
    "\n",
    "Note: SMOTE and scaling already applied in preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "IMPROVED MODEL TRAINING\n",
      "======================================================================\n",
      "\n",
      "[1/2] Optimizing hyperparameters...\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "\n",
      "   âœ… Best parameters:\n",
      "     class_weight: None\n",
      "     max_depth: None\n",
      "     min_samples_leaf: 1\n",
      "     min_samples_split: 2\n",
      "     n_estimators: 200\n",
      "   Best F1 Score (CV): 0.9427\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"IMPROVED MODEL TRAINING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n[1/2] Optimizing hyperparameters...\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [15, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "rf_base = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "grid_search = GridSearchCV(\n",
    "    rf_base,\n",
    "    param_grid,\n",
    "    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
    "    scoring=make_scorer(f1_score),\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\n   âœ… Best parameters:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"     {param}: {value}\")\n",
    "print(f\"   Best F1 Score (CV): {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/2] Evaluating improved model...\n",
      "\n",
      "======================================================================\n",
      "IMPROVED MODEL RESULTS\n",
      "======================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No Stroke       0.96      0.94      0.95       972\n",
      "      Stroke       0.14      0.20      0.17        50\n",
      "\n",
      "    accuracy                           0.90      1022\n",
      "   macro avg       0.55      0.57      0.56      1022\n",
      "weighted avg       0.92      0.90      0.91      1022\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "   True Negatives:   912  (Correctly predicted No Stroke)\n",
      "   False Positives:   60  (Incorrectly predicted Stroke)\n",
      "   False Negatives:   40  (Missed Stroke cases - BAD!)\n",
      "   True Positives:    10  (Correctly predicted Stroke)\n",
      "\n",
      "   AUC-ROC Score: 0.7910\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[2/2] Evaluating improved model...\")\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred_improved = best_model.predict(X_test)\n",
    "y_pred_proba_improved = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"IMPROVED MODEL RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(classification_report(y_test, y_pred_improved, target_names=['No Stroke', 'Stroke']))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred_improved)\n",
    "print(f\"   True Negatives:  {cm[0][0]:4d}  (Correctly predicted No Stroke)\")\n",
    "print(f\"   False Positives: {cm[0][1]:4d}  (Incorrectly predicted Stroke)\")\n",
    "print(f\"   False Negatives: {cm[1][0]:4d}  (Missed Stroke cases - BAD!)\")\n",
    "print(f\"   True Positives:  {cm[1][1]:4d}  (Correctly predicted Stroke)\")\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba_improved)\n",
    "print(f\"\\n   AUC-ROC Score: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "OPTIMAL THRESHOLD SELECTION\n",
      "======================================================================\n",
      "\n",
      "   Default threshold: 0.5\n",
      "   Optimal threshold: 0.335\n",
      "   F1 at optimal threshold: 0.2437\n",
      "\n",
      "   Performance with optimal threshold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No Stroke       0.97      0.87      0.92       972\n",
      "      Stroke       0.16      0.48      0.24        50\n",
      "\n",
      "    accuracy                           0.85      1022\n",
      "   macro avg       0.57      0.68      0.58      1022\n",
      "weighted avg       0.93      0.85      0.89      1022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find optimal threshold\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"OPTIMAL THRESHOLD SELECTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba_improved)\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "optimal_idx = np.argmax(f1_scores)\n",
    "optimal_threshold = thresholds[optimal_idx] if optimal_idx < len(thresholds) else 0.5\n",
    "\n",
    "print(f\"\\n   Default threshold: 0.5\")\n",
    "print(f\"   Optimal threshold: {optimal_threshold:.3f}\")\n",
    "print(f\"   F1 at optimal threshold: {f1_scores[optimal_idx]:.4f}\")\n",
    "\n",
    "y_pred_optimal = (y_pred_proba_improved >= optimal_threshold).astype(int)\n",
    "print(\"\\n   Performance with optimal threshold:\")\n",
    "print(classification_report(y_test, y_pred_optimal, target_names=['No Stroke', 'Stroke']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BASELINE vs IMPROVED COMPARISON\n",
      "======================================================================\n",
      "\n",
      "    Metric  Baseline (RF)  Improved (RF) Improvement\n",
      " Accuracy       0.902153       0.854207      +-5.3%\n",
      "Precision       0.121212       0.163265      +34.7%\n",
      "   Recall       0.160000       0.480000     +200.0%\n",
      " F1 Score       0.137931       0.243655      +76.6%\n",
      "  AUC-ROC       0.000000       0.790957         N/A\n",
      "\n",
      "======================================================================\n",
      "KEY INSIGHTS\n",
      "======================================================================\n",
      "\n",
      "âœ“ False Negatives reduced by: 38.1%\n",
      "  (Fewer missed stroke cases: 42 â†’ 26)\n",
      "\n",
      "âœ“ True Positives increased by: 200.0%\n",
      "  (More stroke cases detected: 8 â†’ 24)\n",
      "\n",
      "ðŸ’¡ The improved model is better for medical screening!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"BASELINE vs IMPROVED COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC-ROC'],\n",
    "    'Baseline (RF)': [\n",
    "        baseline_results['RandomForest']['Accuracy'],\n",
    "        baseline_results['RandomForest']['Precision'],\n",
    "        baseline_results['RandomForest']['Recall'],\n",
    "        baseline_results['RandomForest']['F1 Score'],\n",
    "        0\n",
    "    ],\n",
    "    'Improved (RF)': [\n",
    "        accuracy_score(y_test, y_pred_optimal),\n",
    "        precision_score(y_test, y_pred_optimal),\n",
    "        recall_score(y_test, y_pred_optimal),\n",
    "        f1_score(y_test, y_pred_optimal),\n",
    "        auc_score\n",
    "    ]\n",
    "})\n",
    "\n",
    "comparison['Improvement'] = comparison.apply(\n",
    "    lambda row: f\"+{((row['Improved (RF)'] - row['Baseline (RF)']) / (row['Baseline (RF)'] + 1e-10) * 100):.1f}%\" \n",
    "    if row['Baseline (RF)'] > 0 else 'N/A',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"\\n\", comparison.to_string(index=False))\n",
    "\n",
    "cm_baseline = confusion_matrix(y_test, models['RandomForest'].predict(X_test))\n",
    "cm_improved = confusion_matrix(y_test, y_pred_optimal)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if cm_baseline[1][0] > 0:\n",
    "    fn_reduction = ((cm_baseline[1][0] - cm_improved[1][0]) / cm_baseline[1][0] * 100)\n",
    "    print(f\"\\nâœ“ False Negatives reduced by: {fn_reduction:.1f}%\")\n",
    "    print(f\"  (Fewer missed stroke cases: {cm_baseline[1][0]} â†’ {cm_improved[1][0]})\")\n",
    "\n",
    "if cm_baseline[1][1] > 0:\n",
    "    tp_increase = ((cm_improved[1][1] - cm_baseline[1][1]) / cm_baseline[1][1] * 100)\n",
    "    print(f\"\\nâœ“ True Positives increased by: {tp_increase:.1f}%\")\n",
    "    print(f\"  (More stroke cases detected: {cm_baseline[1][1]} â†’ {cm_improved[1][1]})\")\n",
    "\n",
    "print(\"\\nðŸ’¡ The improved model is better for medical screening!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TOP 10 MOST IMPORTANT FEATURES\n",
      "======================================================================\n",
      "\n",
      "           Feature  Importance\n",
      "              age    0.425884\n",
      "avg_glucose_level    0.187328\n",
      "              bmi    0.149237\n",
      "        work_type    0.074867\n",
      "   smoking_status    0.053145\n",
      "   Residence_type    0.029854\n",
      "           gender    0.025910\n",
      "     ever_married    0.024206\n",
      "     hypertension    0.016049\n",
      "    heart_disease    0.013520\n",
      "\n",
      "ðŸ’¡ Age is typically the strongest predictor of stroke risk\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TOP 10 MOST IMPORTANT FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': best_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\n\", feature_importance.head(10).to_string(index=False))\n",
    "print(\"\\nðŸ’¡ Age is typically the strongest predictor of stroke risk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SAVING MODELS\n",
      "======================================================================\n",
      "\n",
      "âœ“ Baseline model saved: ../Models/stroke_model_baseline.pkl\n",
      "âœ“ Improved model saved: ../Models/stroke_model_improved.pkl\n",
      "âœ“ Metrics saved: ../Models/model_performance_improved.csv\n",
      "âœ“ Comparison saved: ../Models/model_comparison.csv\n",
      "\n",
      "======================================================================\n",
      "âœ… TRAINING COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "To use the improved model in your web app:\n",
      "\n",
      "1. Backup current model:\n",
      "   copy ../Models/stroke_model.pkl ../Models/stroke_model_backup.pkl\n",
      "\n",
      "2. Replace with improved model:\n",
      "   copy ../Models/stroke_model_improved.pkl ../Models/stroke_model.pkl\n",
      "\n",
      "3. Restart the web application\n",
      "\n",
      "4. (Optional) Update threshold in Webapp/utils.py to: 0.335\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SAVING MODELS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save baseline\n",
    "joblib.dump(models['RandomForest'], f'{models_path}stroke_model_baseline.pkl')\n",
    "print(f\"\\nâœ“ Baseline model saved: {models_path}stroke_model_baseline.pkl\")\n",
    "\n",
    "# Save improved\n",
    "joblib.dump(best_model, f'{models_path}stroke_model_improved.pkl')\n",
    "print(f\"âœ“ Improved model saved: {models_path}stroke_model_improved.pkl\")\n",
    "\n",
    "# Save metrics\n",
    "metrics = pd.DataFrame([{\n",
    "    'Model': 'RandomForest_Improved',\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_optimal),\n",
    "    'Precision': precision_score(y_test, y_pred_optimal),\n",
    "    'Recall': recall_score(y_test, y_pred_optimal),\n",
    "    'F1_Score': f1_score(y_test, y_pred_optimal),\n",
    "    'AUC_ROC': auc_score,\n",
    "    'Optimal_Threshold': optimal_threshold\n",
    "}])\n",
    "\n",
    "metrics.to_csv(f'{models_path}model_performance_improved.csv', index=False)\n",
    "print(f\"âœ“ Metrics saved: {models_path}model_performance_improved.csv\")\n",
    "\n",
    "comparison.to_csv(f'{models_path}model_comparison.csv', index=False)\n",
    "print(f\"âœ“ Comparison saved: {models_path}model_comparison.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âœ… TRAINING COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nTo use the improved model in your web app:\")\n",
    "print(\"\\n1. Backup current model:\")\n",
    "print(f\"   copy {models_path}stroke_model.pkl {models_path}stroke_model_backup.pkl\")\n",
    "print(\"\\n2. Replace with improved model:\")\n",
    "print(f\"   copy {models_path}stroke_model_improved.pkl {models_path}stroke_model.pkl\")\n",
    "print(\"\\n3. Restart the web application\")\n",
    "print(f\"\\n4. (Optional) Update threshold in Webapp/utils.py to: {optimal_threshold:.3f}\")\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
